{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "879e0d46-06fa-41d6-8d08-b39166ff4e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10999, 12)\n",
      "Columns: ['ID', 'Warehouse_block', 'Mode_of_Shipment', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases', 'Product_importance', 'Gender', 'Discount_offered', 'Weight_in_gms', 'Reached.on.Time_Y.N']\n",
      "   ID Warehouse_block Mode_of_Shipment  Customer_care_calls  Customer_rating  \\\n",
      "0   1               D           Flight                    4                2   \n",
      "1   2               F           Flight                    4                5   \n",
      "2   3               A           Flight                    2                2   \n",
      "\n",
      "   Cost_of_the_Product  Prior_purchases Product_importance Gender  \\\n",
      "0                  177                3                low      F   \n",
      "1                  216                2                low      M   \n",
      "2                  183                4                low      M   \n",
      "\n",
      "   Discount_offered  Weight_in_gms  Reached.on.Time_Y.N  \n",
      "0                44           1233                    1  \n",
      "1                59           3088                    1  \n",
      "2                48           3374                    1  \n",
      "\n",
      "Target (Reached.on.Time_Y.N) value counts:\n",
      "Reached.on.Time_Y.N\n",
      "1    6563\n",
      "0    4436\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dtypes:\n",
      "ID                      int64\n",
      "Warehouse_block        object\n",
      "Mode_of_Shipment       object\n",
      "Customer_care_calls     int64\n",
      "Customer_rating         int64\n",
      "Cost_of_the_Product     int64\n",
      "Prior_purchases         int64\n",
      "Product_importance     object\n",
      "Gender                 object\n",
      "Discount_offered        int64\n",
      "Weight_in_gms           int64\n",
      "Reached.on.Time_Y.N     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CSV_PATH = \"/Users/burakbozatli/Desktop/data/shippingdata.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"\\nTarget (Reached.on.Time_Y.N) value counts:\")\n",
    "print(df[\"Reached.on.Time_Y.N\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nDtypes:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7908f5-ba67-40f9-9a82-0579b20024f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hedef kolon: Reached.on.Time_Y.N (1=on-time, 0=late). Sƒ±nƒ±f daƒüƒ±lƒ±mƒ±: 6563 / 4436 ‚Üí √ßok dengesiz deƒüil, ama 1‚Äôler biraz fazla.\n",
    "#Tipler: kategorikler (Warehouse_block, Mode_of_Shipment, Product_importance, Gender) object; sayƒ±sallar int. Beklenen gibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "115bb923-c2e1-4074-b621-14e96443541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse_block        0\n",
      "Mode_of_Shipment       0\n",
      "Customer_care_calls    0\n",
      "Customer_rating        0\n",
      "Cost_of_the_Product    0\n",
      "Prior_purchases        0\n",
      "Product_importance     0\n",
      "Gender                 0\n",
      "Discount_offered       0\n",
      "Weight_in_gms          0\n",
      "Reached.on.Time_Y.N    0\n",
      "OnTime                 0\n",
      "dtype: int64\n",
      "OnTime\n",
      "1    6563\n",
      "0    4436\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.copy()\n",
    "df[\"OnTime\"] = df[\"Reached.on.Time_Y.N\"]\n",
    "df = df.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "\n",
    "print(df.isna().sum().sort_values(ascending=False))\n",
    "print(df[\"OnTime\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c68ca2ac-731c-4501-a01f-3bf799bd10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']\n",
      "Numeric: ['Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']\n",
      "Train: (8799, 10) Test: (2200, 10) | OnTime=1 (train): 5250 of 8799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "\n",
    "y = df[\"OnTime\"]\n",
    "X = df.drop(columns=[\"OnTime\", \"Reached.on.Time_Y.N\"])\n",
    "\n",
    "cat_cols = [\"Warehouse_block\", \"Mode_of_Shipment\", \"Product_importance\", \"Gender\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numeric:\", num_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape,\n",
    "      \"| OnTime=1 (train):\", int(y_train.sum()), \"of\", y_train.shape[0])\n",
    "\n",
    "pre_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "pre_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b83ecd-d184-4e7c-9d9b-b82b2653c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR @th=0.40] acc=0.639 prec=0.706 rec=0.676 f1=0.691 auc=0.717 | fit_s=0.03s\n",
      "CM:\n",
      " [[518 369]\n",
      " [426 887]]\n",
      "\n",
      "Report @0.40:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.549     0.584     0.566       887\n",
      "           1      0.706     0.676     0.691      1313\n",
      "\n",
      "    accuracy                          0.639      2200\n",
      "   macro avg      0.627     0.630     0.628      2200\n",
      "weighted avg      0.643     0.639     0.640      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "TH_40 = 0.40\n",
    "\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    (\"prep\", pre_lr),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "t0 = time.time()\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "fit_s_lr = time.time() - t0\n",
    "\n",
    "y_proba = pipe_lr.predict_proba(X_test)[:, 1]\n",
    "y_pred  = (y_proba >= TH_40).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec  = recall_score(y_test, y_pred)\n",
    "f1   = f1_score(y_test, y_pred)\n",
    "roc  = roc_auc_score(y_test, y_proba)\n",
    "cm   = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"[LR @th=0.40] acc={acc:.3f} prec={prec:.3f} rec={rec:.3f} f1={f1:.3f} auc={roc:.3f} | fit_s={fit_s_lr:.2f}s\")\n",
    "print(\"CM:\\n\", cm)\n",
    "print(\"\\nReport @0.40:\\n\", classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46e591-582a-4a3d-88c3-feadc14ef466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC=0.717 ‚Üí ayƒ±rma g√ºc√º fena deƒüil.\n",
    "#th=0.40‚Äôta P=0.706 / R=0.676 / F1=0.691: dengeli; ama FP=369, FN=426 (CM‚Äôden).\n",
    "#ihtiyaca g√∂re e≈üiƒüi oynatmak mantƒ±klƒ± (FP‚Üì i√ßin th‚Üë, FN‚Üì i√ßin th‚Üì)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a815ef5-b7b3-432c-8f21-b90d98a151ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Best F1 threshold ‚âà 0.177 | P=0.598 R=0.998 F1=0.748\n",
      "CM @best_th:\n",
      " [[   5  882]\n",
      " [   3 1310]]\n",
      "Report @best_th:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.625     0.006     0.011       887\n",
      "           1      0.598     0.998     0.748      1313\n",
      "\n",
      "    accuracy                          0.598      2200\n",
      "   macro avg      0.611     0.502     0.379      2200\n",
      "weighted avg      0.609     0.598     0.451      2200\n",
      "\n",
      "[LR] th for recall‚â•0.80: 0.141 | P=0.597 R=1.000\n",
      "[[   0  887]\n",
      " [   0 1313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       887\n",
      "           1      0.597     1.000     0.748      1313\n",
      "\n",
      "    accuracy                          0.597      2200\n",
      "   macro avg      0.298     0.500     0.374      2200\n",
      "weighted avg      0.356     0.597     0.446      2200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "prec_arr, rec_arr, th_arr = precision_recall_curve(y_test, y_proba)\n",
    "f1s = 2 * (prec_arr * rec_arr) / (prec_arr + rec_arr + 1e-12)\n",
    "\n",
    "best_idx = int(f1s.argmax())\n",
    "best_th = th_arr[best_idx-1] if best_idx > 0 else 0.5\n",
    "print(f\"[LR] Best F1 threshold ‚âà {best_th:.3f} | P={prec_arr[best_idx]:.3f} R={rec_arr[best_idx]:.3f} F1={f1s[best_idx]:.3f}\")\n",
    "\n",
    "y_pred_best = (y_proba >= best_th).astype(int)\n",
    "print(\"CM @best_th:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"Report @best_th:\\n\", classification_report(y_test, y_pred_best, digits=3))\n",
    "\n",
    "target_recall = 0.80\n",
    "idx = np.where(rec_arr >= target_recall)[0]\n",
    "if len(idx):\n",
    "    i = idx[0]\n",
    "    th_recall = th_arr[i-1] if i > 0 else th_arr[0]\n",
    "    y_pred_r = (y_proba >= th_recall).astype(int)\n",
    "    print(f\"[LR] th for recall‚â•{target_recall:.2f}: {th_recall:.3f} | P={prec_arr[i]:.3f} R={rec_arr[i]:.3f}\")\n",
    "    print(confusion_matrix(y_test, y_pred_r))\n",
    "    print(classification_report(y_test, y_pred_r, digits=3))\n",
    "else:\n",
    "    print(f\"[LR] recall‚â•{target_recall:.2f} saƒülanamadƒ±.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eec62bbe-7027-4f6d-90e8-bcf1fc690f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/09/16 14:59:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLflow] Logged LR run: logistics-demo / lr-th-0p40\n"
     ]
    }
   ],
   "source": [
    "RUN_MLFLOW = True\n",
    "try:\n",
    "    import mlflow, mlflow.sklearn\n",
    "    from mlflow.models.signature import infer_signature\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "except Exception:\n",
    "    RUN_MLFLOW = False\n",
    "\n",
    "if RUN_MLFLOW:\n",
    "    ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"lr-th-0p40\"):\n",
    "        mlflow.log_param(\"model\", \"LogisticRegression\")\n",
    "        mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "        mlflow.log_param(\"threshold\", 0.40)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", float(acc))\n",
    "        mlflow.log_metric(\"precision\", float(prec))\n",
    "        mlflow.log_metric(\"recall\", float(rec))\n",
    "        mlflow.log_metric(\"f1\", float(f1))\n",
    "        mlflow.log_metric(\"roc_auc\", float(roc))\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(cm); ax.set_title(\"CM LR @th=0.40\")\n",
    "        for (i, j), v in np.ndenumerate(cm):\n",
    "            ax.text(j, i, int(v), ha=\"center\", va=\"center\")\n",
    "        p = ART_DIR / \"cm_lr_th040.png\"\n",
    "        fig.tight_layout(); fig.savefig(p, dpi=150); plt.close(fig)\n",
    "        mlflow.log_artifact(str(p), artifact_path=\"plots\")\n",
    "\n",
    "        signature = infer_signature(X_train, pipe_lr.predict(X_train))\n",
    "        mlflow.sklearn.log_model(pipe_lr, \"model\", signature=signature)\n",
    "\n",
    "    print(\"[MLflow] Logged LR run: logistics-demo / lr-th-0p40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b77c0b8-793b-40da-98cc-e33164f62fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cb4e694-3d0f-4e3e-bd37-a80ad9539cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] RF retrain done in 1.34s\n",
      "\n",
      "[RF] @th=0.40: {'th': 0.4, 'acc': 0.6213636363636363, 'prec': 0.636830102622577, 'rec': 0.8507235338918507, 'f1': 0.7283990870557548, 'auc': 0.7372549760396212, 'cm': [[250, 637], [196, 1117]]}\n",
      "[RF] @th=0.50: {'th': 0.5, 'acc': 0.6654545454545454, 'prec': 0.8312284730195177, 'rec': 0.5514089870525514, 'f1': 0.663003663003663, 'auc': 0.7372549760396212, 'cm': [[740, 147], [589, 724]]}\n",
      "\n",
      "[RF] Best F1 in 0.40‚Äì0.55: {'th': 0.4, 'f1': 0.7283990870557548, 'acc': 0.6213636363636363, 'prec': 0.636830102622577, 'rec': 0.8507235338918507, 'cm': [[250, 637], [196, 1117]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLflow] RF model logged with signature & input_example\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "\n",
    "try:\n",
    "    pre_rf\n",
    "except NameError:\n",
    "    pre_rf = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols),\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "RF_PARAMS = dict(\n",
    "    n_estimators=1000, max_depth=14, max_features=\"sqrt\",\n",
    "    min_samples_leaf=2, bootstrap=True, max_samples=0.8,\n",
    "    n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    (\"prep\", pre_rf),\n",
    "    (\"rf\", RandomForestClassifier(**RF_PARAMS))\n",
    "])\n",
    "\n",
    "t0 = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "fit_s = time.time() - t0\n",
    "print(f\"[INFO] RF retrain done in {fit_s:.2f}s\")\n",
    "\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def eval_at(th):\n",
    "    pred = (proba_rf >= th).astype(int)\n",
    "    return {\n",
    "        \"th\": th,\n",
    "        \"acc\": accuracy_score(y_test, pred),\n",
    "        \"prec\": precision_score(y_test, pred),\n",
    "        \"rec\":  recall_score(y_test, pred),\n",
    "        \"f1\":   f1_score(y_test, pred),\n",
    "        \"auc\":  roc_auc_score(y_test, proba_rf),\n",
    "        \"cm\":   confusion_matrix(y_test, pred)\n",
    "    }\n",
    "\n",
    "res_040 = eval_at(0.40)\n",
    "res_050 = eval_at(0.50)\n",
    "print(\"\\n[RF] @th=0.40:\", {k:(float(v) if k!='cm' else v.tolist()) for k,v in res_040.items()})\n",
    "print(\"[RF] @th=0.50:\", {k:(float(v) if k!='cm' else v.tolist()) for k,v in res_050.items()})\n",
    "\n",
    "best = {\"th\": None, \"f1\": -1}\n",
    "for th in np.arange(0.40, 0.551, 0.01):\n",
    "    pred = (proba_rf >= th).astype(int)\n",
    "    f1v = f1_score(y_test, pred)\n",
    "    if f1v > best[\"f1\"]:\n",
    "        best = {\n",
    "            \"th\": float(th),\n",
    "            \"f1\": float(f1v),\n",
    "            \"acc\": float(accuracy_score(y_test, pred)),\n",
    "            \"prec\": float(precision_score(y_test, pred)),\n",
    "            \"rec\": float(recall_score(y_test, pred)),\n",
    "            \"cm\": confusion_matrix(y_test, pred).tolist()\n",
    "        }\n",
    "print(\"\\n[RF] Best F1 in 0.40‚Äì0.55:\", best)\n",
    "\n",
    "RUN_MLFLOW = True\n",
    "try:\n",
    "    import mlflow, mlflow.sklearn\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mlflow.models.signature import infer_signature\n",
    "except Exception:\n",
    "    RUN_MLFLOW = False\n",
    "\n",
    "if RUN_MLFLOW:\n",
    "    ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    cm040 = res_040[\"cm\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cm040); ax.set_title(\"CM RF @th=0.40\")\n",
    "    for (i, j), v in np.ndenumerate(cm040): ax.text(j, i, int(v), ha=\"center\", va=\"center\")\n",
    "    p = ART_DIR / \"cm_rf_th040.png\"\n",
    "    fig.tight_layout(); fig.savefig(p, dpi=150); plt.close(fig)\n",
    "\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"rf-full-th040\"):\n",
    "        mlflow.log_params(RF_PARAMS)\n",
    "        mlflow.log_param(\"threshold\", 0.40)\n",
    "        mlflow.log_metric(\"acc_at_040\", float(res_040[\"acc\"]))\n",
    "        mlflow.log_metric(\"prec_at_040\", float(res_040[\"prec\"]))\n",
    "        mlflow.log_metric(\"rec_at_040\",  float(res_040[\"rec\"]))\n",
    "        mlflow.log_metric(\"f1_at_040\",   float(res_040[\"f1\"]))\n",
    "        mlflow.log_metric(\"auc_at_040\",  float(res_040[\"auc\"]))\n",
    "        mlflow.log_metric(\"best_f1_in_040_055\", float(best[\"f1\"]))\n",
    "        mlflow.log_artifact(str(p), artifact_path=\"plots\")\n",
    "\n",
    "        signature = infer_signature(X_train, rf.predict(X_train))\n",
    "        input_example = X_train.head(1)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=rf,\n",
    "            name=\"rf_model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "    print(\"[MLflow] RF model logged with signature & input_example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959c96f-9517-4853-8590-f278d4cd8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#th=0.40: acc=0.621, prec=0.637, rec=0.851, F1=0.728, AUC=0.737\n",
    "#‚Üí recall g√º√ßl√º (gecikmeleri daha √ßok yakalƒ±yor), F1 de LR‚Äôdan y√ºksek (LR F1‚âà0.691).\n",
    "#th=0.50: acc=0.666, prec=0.831, rec=0.551, F1=0.663\n",
    "#‚Üí precision g√º√ßl√º, ama recall d√º≈ü√ºyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "805c2297-c6f5-4c8a-bc05-0acf9394ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-15 permutation importance (roc_auc):\n",
      "Weight_in_gms          0.083637\n",
      "Discount_offered       0.026240\n",
      "Cost_of_the_Product    0.002189\n",
      "Mode_of_Shipment       0.000986\n",
      "Warehouse_block       -0.000744\n",
      "Gender                -0.001687\n",
      "Customer_rating       -0.002084\n",
      "Customer_care_calls   -0.003019\n",
      "Prior_purchases       -0.004328\n",
      "Product_importance    -0.008837\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "r = permutation_importance(\n",
    "    rf, X_test, y_test,\n",
    "    scoring=\"roc_auc\", n_repeats=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "feat_names = rf.named_steps[\"prep\"].get_feature_names_out()\n",
    "imp = pd.Series(r.importances_mean, index=feat_names).sort_values(ascending=False)\n",
    "\n",
    "imp.index = [s.replace(\"cat__\", \"\").replace(\"num__\", \"\") for s in imp.index]\n",
    "\n",
    "print(\"Top-15 permutation importance (roc_auc):\")\n",
    "print(imp.head(15).round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1945b-3f9d-467b-8acf-094f4c1f029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms a√ßƒ±k ara en faydalƒ± sinyal.\n",
    "#Discount_offered ikinci; indirim arttƒ±k√ßa gecikme/‚Äúon-time‚Äù olasƒ±lƒ±ƒüƒ± nasƒ±l deƒüi≈üiyor, kontrol etmeye deƒüer.\n",
    "#Diƒüerlerinin negatif olmasƒ± ‚Äúk√∂t√º etkiliyor‚Äù demek deƒüil;\n",
    "#perm√ºtasyon g√ºr√ºlt√ºs√º ve etkile≈üim/kollinearite y√ºz√ºnden ortalama etki sƒ±fƒ±r civarƒ±nda \n",
    "#model onlar olmadan da benzer performansƒ± yakalƒ±yor olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "365bd0b5-7536-42d5-a1d4-49a1d550b07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Weight_in_gms] bin -> n, mean_proba, ontime_rate@0.5\n",
      "         bin   n  mean_proba  ontime_rate\n",
      "[1002, 1329) 220    0.688896     0.568182\n",
      "[1329, 1664) 220    0.671765     0.513636\n",
      "[1664, 2029) 220    0.669726     0.581818\n",
      "[2029, 3364) 220    0.984323     1.000000\n",
      "[3364, 4201) 220    0.730377     0.672727\n",
      "[4201, 4531) 221    0.430454     0.108597\n",
      "[4531, 4889) 219    0.425446     0.123288\n",
      "[4889, 5265) 220    0.432068     0.113636\n",
      "[5265, 5624) 220    0.429576     0.122727\n",
      "[5624, 7588) 220    0.443025     0.154545\n",
      "\n",
      "[Discount_offered] bin -> n, mean_proba, ontime_rate@0.5\n",
      "     bin   n  mean_proba  ontime_rate\n",
      "  [1, 2) 331    0.482168     0.265861\n",
      "  [2, 3) 184    0.465972     0.250000\n",
      "  [3, 4) 161    0.439662     0.136646\n",
      "  [4, 6) 334    0.476995     0.224551\n",
      "  [6, 7) 186    0.456708     0.166667\n",
      "  [7, 8) 142    0.448488     0.183099\n",
      " [8, 10) 341    0.457008     0.181818\n",
      "[10, 19)  88    0.994867     1.000000\n",
      "[19, 45) 222    0.997397     1.000000\n",
      "[45, 65) 211    0.997002     1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_te = X_test.copy()\n",
    "X_te[\"proba_rf\"] = proba_rf\n",
    "\n",
    "def binned_table(col, q=10):\n",
    "    bins = np.unique(np.quantile(X_te[col].astype(float), np.linspace(0,1,q+1)))\n",
    "    labels = [f\"[{bins[i]:.0f}, {bins[i+1]:.0f})\" for i in range(len(bins)-1)]\n",
    "    cut = pd.cut(X_te[col].astype(float), bins=bins, include_lowest=True, labels=labels)\n",
    "    tbl = (\n",
    "        X_te.groupby(cut, observed=True)\n",
    "            .agg(n=(\"proba_rf\",\"size\"),\n",
    "                 mean_proba=(\"proba_rf\",\"mean\"),\n",
    "                 ontime_rate=(\"proba_rf\", lambda s: np.mean((s>=0.5).astype(int))))\n",
    "            .reset_index()\n",
    "            .rename(columns={col:\"bin\"})\n",
    "    )\n",
    "    return tbl\n",
    "\n",
    "tbl_w = binned_table(\"Weight_in_gms\", q=10)\n",
    "tbl_d = binned_table(\"Discount_offered\", q=10)\n",
    "\n",
    "print(\"\\n[Weight_in_gms] bin -> n, mean_proba, ontime_rate@0.5\")\n",
    "print(tbl_w.to_string(index=False))\n",
    "\n",
    "print(\"\\n[Discount_offered] bin -> n, mean_proba, ontime_rate@0.5\")\n",
    "print(tbl_d.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69908e66-88ed-460e-a651-70c5bbc12642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms: 4.2‚Äì5.6kg civarƒ±nda mean_proba ‚âà 0.43 ve on-time oranƒ± √ßok d√º≈ü√ºk ‚Üí bu aralƒ±k gecikme riski y√ºksek.\n",
    "#Buna kar≈üƒ±lƒ±k 2.0‚Äì3.36kg aralƒ±ƒüƒ±nda mean_proba ~0.98 ve on-time %100 ü§®\n",
    "#Discount_offered: %10+ indirimlerde mean_proba ‚âà 0.995‚Äì0.997 ve on-time %100.\n",
    "#Bu da ‚Äúindirim y√ºksekse hep zamanƒ±nda‚Äù gibi basamaklƒ± bir davranƒ±≈ü g√∂steriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f0f0779-f677-46ba-84d4-3a9d4031ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnTime rate by high_disc:\n",
      " high_disc\n",
      "0    0.470981\n",
      "1    0.865906\n",
      "Name: OnTime, dtype: float64\n",
      "\n",
      "OnTime rate by weight bucket:\n",
      " w_bucket\n",
      "<2029        0.706061\n",
      "2029-3364    1.000000\n",
      "3364-4201    0.763636\n",
      "4201-5624    0.419318\n",
      ">=5624       0.409091\n",
      "Name: OnTime, dtype: float64\n",
      "\n",
      "OnTime by high_disc x Mode_of_Shipment:\n",
      "Mode_of_Shipment    Flight      Road      Ship\n",
      "high_disc                                     \n",
      "0                 0.454545  0.492126  0.469591\n",
      "1                 0.878261  0.824074  0.872385\n",
      "\n",
      "Counts by high_disc x Mode_of_Shipment:\n",
      "Mode_of_Shipment  Flight  Road  Ship\n",
      "high_disc                           \n",
      "0                    242   254  1003\n",
      "1                    115   108   478\n",
      "\n",
      "OnTime by weight bucket x Mode_of_Shipment:\n",
      "Mode_of_Shipment    Flight      Road      Ship\n",
      "w_bucket                                      \n",
      "<2029             0.696629  0.714286  0.706009\n",
      "2029-3364         1.000000  1.000000  1.000000\n",
      "3364-4201         0.676471  0.914286  0.748344\n",
      "4201-5624         0.436709  0.392157  0.421793\n",
      ">=5624            0.406250  0.450000  0.398649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/jfs9sfcd1t56yn93r71pt2km0000gn/T/ipykernel_43869/4264605827.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  print(\"\\nOnTime rate by weight bucket:\\n\", X_te.groupby(\"w_bucket\")[\"OnTime\"].mean())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_te = X_test.copy()\n",
    "X_te[\"OnTime\"] = y_test.values\n",
    "\n",
    "X_te[\"high_disc\"] = (X_te[\"Discount_offered\"] >= 10).astype(int)\n",
    "print(\"OnTime rate by high_disc:\\n\", X_te.groupby(\"high_disc\")[\"OnTime\"].mean())\n",
    "\n",
    "bins_w = [X_te[\"Weight_in_gms\"].min()-1, 2029, 3364, 4201, 5624, X_te[\"Weight_in_gms\"].max()+1]\n",
    "labels_w = [\"<2029\", \"2029-3364\", \"3364-4201\", \"4201-5624\", \">=5624\"]\n",
    "X_te[\"w_bucket\"] = pd.cut(X_te[\"Weight_in_gms\"], bins=bins_w, labels=labels_w, include_lowest=True)\n",
    "print(\"\\nOnTime rate by weight bucket:\\n\", X_te.groupby(\"w_bucket\")[\"OnTime\"].mean())\n",
    "\n",
    "print(\"\\nOnTime by high_disc x Mode_of_Shipment:\")\n",
    "print(pd.crosstab(X_te[\"high_disc\"], X_te[\"Mode_of_Shipment\"], values=X_te[\"OnTime\"], aggfunc=\"mean\"))\n",
    "\n",
    "print(\"\\nCounts by high_disc x Mode_of_Shipment:\")\n",
    "print(pd.crosstab(X_te[\"high_disc\"], X_te[\"Mode_of_Shipment\"]))\n",
    "\n",
    "print(\"\\nOnTime by weight bucket x Mode_of_Shipment:\")\n",
    "print(pd.crosstab(X_te[\"w_bucket\"], X_te[\"Mode_of_Shipment\"], values=X_te[\"OnTime\"], aggfunc=\"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca520e6-99f7-4ca9-a4d4-e6fa27739200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Discount etkisi\n",
    "#High discount (‚â•20‚Äì45 arasƒ± gibi) verilenlerde OnTime oranƒ± %100‚Äôe √ßƒ±kmƒ±≈ü.\n",
    "#Buna kar≈üƒ±lƒ±k d√º≈ü√ºk indirimlerde (1‚Äì10 arasƒ±) OnTime oranƒ± %18‚Äì26 civarƒ±nda kalƒ±yor.\n",
    "#Yani indirim, m√º≈üteri i√ßin deƒüil ama lojistik operasyon i√ßin g√º√ßl√º bir sinyal gibi davranƒ±yor.\n",
    "#2) Weight (aƒüƒ±rlƒ±k) etkisi\n",
    "#2029‚Äì3364 gr. aralƒ±ƒüƒ±nda %100 zamanƒ±nda teslim var.\n",
    "#3364‚Äì4201 gr. aralƒ±ƒüƒ±nda %76 civarƒ±nda.\n",
    "#Ama 4201+ gr. olduƒüunda oran %40‚Äôa kadar d√º≈ü√ºyor.\n",
    "#Demek ki aƒüƒ±rlƒ±k arttƒ±k√ßa zamanƒ±nda teslim ihtimali d√º≈ü√ºyor.\n",
    "#3) Mode of Shipment (kargo tipi) √ó indirim\n",
    "#High discount verilenlerde b√ºt√ºn ta≈üƒ±ma tipleri %82‚Äì87 arasƒ± ba≈üarƒ±yla gidiyor.\n",
    "#D√º≈ü√ºk discount verilenlerde %45‚Äì49 arasƒ± kalƒ±yor.\n",
    "#Discount, shipment tipinden baƒüƒ±msƒ±z olarak g√º√ßl√º bir fakt√∂r.\n",
    "#4) Mode of Shipment √ó Weight\n",
    "#Hafif paketlerde (‚â§2029) b√ºt√ºn ta≈üƒ±ma tipleri %70 civarƒ±nda.\n",
    "#Orta aƒüƒ±rlƒ±klarda (2029‚Äì3364) %100 ba≈üarƒ±.\n",
    "#Aƒüƒ±r paketlerde (4200 √ºst√º) b√ºt√ºn ta≈üƒ±ma tiplerinde %39‚Äì43‚Äôe kadar d√º≈ü√ºyor.\n",
    "#Ta≈üƒ±ma tipinden √ßok aƒüƒ±rlƒ±k belirleyici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe77ff51-4d6d-43ab-93fe-e15751591489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: artifacts/permutation_importance.csv\n",
      "saved: artifacts/permutation_importance_top20.png\n",
      "[MLflow] logged permutation importance artifacts\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "r = permutation_importance(\n",
    "    rf, X_test, y_test,\n",
    "    scoring=\"roc_auc\", n_repeats=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "feat_names = rf.named_steps[\"prep\"].get_feature_names_out()\n",
    "pi = pd.Series(r.importances_mean, index=feat_names).sort_values(ascending=True)\n",
    "\n",
    "pi.index = [s.replace(\"cat__\", \"\").replace(\"num__\", \"\") for s in pi.index]\n",
    "\n",
    "pi_path = ART_DIR / \"permutation_importance.csv\"\n",
    "pi.to_csv(pi_path, header=[\"importance\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "pi.tail(20).plot(kind=\"barh\", ax=ax)\n",
    "ax.set_title(\"Permutation Importance (top 20) ‚Äî scoring=roc_auc\")\n",
    "ax.set_xlabel(\"Œî roc_auc\")\n",
    "fig.tight_layout()\n",
    "pi_png = ART_DIR / \"permutation_importance_top20.png\"\n",
    "fig.savefig(pi_png, dpi=150); plt.close(fig)\n",
    "\n",
    "print(f\"saved: {pi_path}\")\n",
    "print(f\"saved: {pi_png}\")\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"rf-permutation-importance\"):\n",
    "        mlflow.log_artifact(str(pi_path), artifact_path=\"analysis\")\n",
    "        mlflow.log_artifact(str(pi_png), artifact_path=\"plots\")\n",
    "    print(\"[MLflow] logged permutation importance artifacts\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785af923-35c7-4bd0-b59a-dcb87883f5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a4cbe-b87e-44d1-ab40-5d73bd0401c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82275274-ea95-4753-99fd-9016226edfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms (~0.084 ŒîAUC): a√ßƒ±k ara en kritik sinyal. Bu √∂zelliƒüi bozunca test ROC-AUC ~0.084 d√º≈ü√ºyor.\n",
    "#Discount_offered (~0.026 ŒîAUC): ikinci g√º√ßl√º sinyal.\n",
    "#Geri kalanƒ± ‚âà0 ya da hafif negatif: tek ba≈üƒ±na bozduƒüunda modelin AUC‚Äôsi neredeyse deƒüi≈ümiyor ‚Üí katkƒ±larƒ± marjinal / etkile≈üimlere baƒüƒ±mlƒ±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc8c6b00-5c16-42d1-9589-7a12964554a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: artifacts/binned_proba_Weight_in_gms.png\n",
      "saved: artifacts/binned_table_Weight_in_gms.csv\n",
      "saved: artifacts/binned_proba_Discount_offered.png\n",
      "saved: artifacts/binned_table_Discount_offered.csv\n",
      "[MLflow] logged binned plots & tables (fixed)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "X_te = X_test.copy()\n",
    "X_te[\"proba_rf\"] = proba_rf\n",
    "X_te[\"OnTime\"]   = y_test.values\n",
    "\n",
    "def make_binned_plot(col, q=10):\n",
    "    # quantile bin'leri ve etiketler\n",
    "    bins = np.unique(np.quantile(X_te[col].astype(float), np.linspace(0, 1, q+1)))\n",
    "    labels = [f\"[{bins[i]:.0f},{bins[i+1]:.0f})\" for i in range(len(bins)-1)]\n",
    "    cut = pd.cut(X_te[col].astype(float), bins=bins, include_lowest=True, labels=labels)\n",
    "\n",
    "    tbl = (\n",
    "        X_te.groupby(cut, observed=True)\n",
    "            .agg(n=(\"proba_rf\",\"size\"),\n",
    "                 mean_proba=(\"proba_rf\",\"mean\"),\n",
    "                 ontime_rate=(\"OnTime\",\"mean\"))\n",
    "            .reset_index()\n",
    "            .rename(columns={col:\"bin\"})\n",
    "    )\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(9, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(range(len(tbl)), tbl[\"mean_proba\"], marker=\"o\", label=\"Mean Pred Proba\")\n",
    "    ax1.plot(range(len(tbl)), tbl[\"ontime_rate\"], marker=\"s\", label=\"OnTime Rate\")\n",
    "    ax2.bar(range(len(tbl)), tbl[\"n\"], alpha=0.25, label=\"Count\")\n",
    "\n",
    "    ax1.set_title(f\"Binned probability ‚Äî {col}\")\n",
    "    ax1.set_ylabel(\"Rate / Probability\")\n",
    "    ax2.set_ylabel(\"Bin Count\")\n",
    "\n",
    "    ax1.set_xticks(range(len(tbl[\"bin\"])))\n",
    "    ax1.set_xticklabels(tbl[\"bin\"], rotation=45, ha=\"right\")\n",
    "\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_png = ART_DIR / f\"binned_proba_{col}.png\"\n",
    "    out_csv = ART_DIR / f\"binned_table_{col}.csv\"\n",
    "    fig.savefig(out_png, dpi=150); plt.close(fig)\n",
    "    tbl.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"saved: {out_png}\")\n",
    "    print(f\"saved: {out_csv}\")\n",
    "    return out_png, out_csv\n",
    "\n",
    "p1_png, p1_csv = make_binned_plot(\"Weight_in_gms\", q=10)\n",
    "p2_png, p2_csv = make_binned_plot(\"Discount_offered\", q=10)\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"rf-binned-plots-fixed\"):\n",
    "        for p in [p1_png, p2_png]:\n",
    "            mlflow.log_artifact(str(p), artifact_path=\"plots\")\n",
    "        for c in [p1_csv, p2_csv]:\n",
    "            mlflow.log_artifact(str(c), artifact_path=\"analysis\")\n",
    "    print(\"[MLflow] logged binned plots & tables (fixed)\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d4a22-497c-4f50-8149-2ea06804e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms (tablo/grafik):\n",
    "#4.2‚Äì5.6 kg (√∂r. [4201,4531), [4531,4889), [4889,5265), [5265,5624)) dilimlerinde on-time rate ‚âà %40‚Äì48 ‚Üí belirgin risk bandƒ±.\n",
    "#2.0‚Äì3.36 kg civarƒ± dilimlerde oran √ßok y√ºksek.\n",
    "#Modelin mean predicted probasƒ± da aynƒ± paterni takip ediyor ‚Üí model & veri uyumlu.\n",
    "#Discount_offered (tablo/grafik):\n",
    "#%10‚Äì%19 ve %19‚Äì%45 dilimlerinde on-time rate ‚âà 1.0 ve mean proba ‚âà 0.995‚Äì0.997 ‚Üí pratikte ‚Äúgaranti‚Äù b√∂lge.\n",
    "#%1‚Äì%8 arasƒ± dilimlerde hem oran hem proba d√º≈ü√ºk/orta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43e76ce5-1e45-407e-943d-fbb47c28f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking_uri = file:///Users/burakbozatli/mlruns\n",
      "registry_uri = file:///Users/burakbozatli/mlruns\n",
      "latest version: 2 | status: READY | stage: Staging\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "REG_NAME = \"logistics-on-time\"\n",
    "print(\"tracking_uri =\", mlflow.get_tracking_uri())\n",
    "print(\"registry_uri =\", mlflow.get_registry_uri())\n",
    "\n",
    "client = MlflowClient()\n",
    "vers = client.search_model_versions(f\"name='{REG_NAME}'\")\n",
    "assert vers, \"Registry'de versiyon bulunamadƒ±.\"\n",
    "latest = max(vers, key=lambda v: int(v.version))\n",
    "print(\"latest version:\", latest.version, \"| status:\", latest.status, \"| stage:\", latest.current_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "304144e9-a576-419e-bda3-78045cb9e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] registry_uri = file:///Users/burakbozatli/mlruns\n",
      "[info] base_dir     = /Users/burakbozatli/mlruns\n",
      "[info] hedef versiyon = v2\n",
      "[ok] yedek alƒ±ndƒ± ‚Üí /Users/burakbozatli/mlruns/models/logistics-on-time/version-2/meta.yaml.bak-20250916-174353\n",
      "[ok] meta.yaml g√ºncellendi ‚Üí stage='Staging'\n",
      "[verify] current_stage: Staging | version: 2\n",
      "\n",
      " MLflow UI ‚Üí Models ‚Üílogistics-on-time‚Üí Versions ‚Üí v2 .\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, time, re, sys\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "except Exception:\n",
    "    raise RuntimeError(\"PyYAML gerekli. Kur: pip install pyyaml\")\n",
    "\n",
    "REG_NAME   = \"logistics-on-time\" \n",
    "TARGET_STAGE = \"Staging\"         \n",
    "TARGET_VERSION = None            \n",
    "\n",
    "reg_uri = mlflow.get_registry_uri()\n",
    "if not reg_uri.startswith(\"file://\"):\n",
    "    raise SystemExit(f\"Registry file-store deƒüil: {reg_uri} (Bu yama sadece file:// i√ßin)\")\n",
    "\n",
    "base_dir = Path(reg_uri.replace(\"file://\", \"\"))\n",
    "if not base_dir.exists():\n",
    "    raise SystemExit(f\"Registry dizini yok: {base_dir}\")\n",
    "\n",
    "print(\"[info] registry_uri =\", reg_uri)\n",
    "print(\"[info] base_dir     =\", base_dir)\n",
    "\n",
    "client = MlflowClient()\n",
    "vers = client.search_model_versions(f\"name='{REG_NAME}'\")\n",
    "if not vers:\n",
    "    raise SystemExit(f\"Model bulunamadƒ±: {REG_NAME}\")\n",
    "\n",
    "if TARGET_VERSION is None:\n",
    "    TARGET_VERSION = max(int(v.version) for v in vers)\n",
    "print(f\"[info] hedef versiyon = v{TARGET_VERSION}\")\n",
    "\n",
    "meta_dir = base_dir / \"models\" / REG_NAME / f\"version-{TARGET_VERSION}\"\n",
    "meta_path = meta_dir / \"meta.yaml\"\n",
    "if not meta_path.exists():\n",
    "    raise SystemExit(f\"meta.yaml bulunamadƒ±: {meta_path}\")\n",
    "\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "backup_path = meta_dir / f\"meta.yaml.bak-{ts}\"\n",
    "shutil.copy2(meta_path, backup_path)\n",
    "print(f\"[ok] yedek alƒ±ndƒ± ‚Üí {backup_path}\")\n",
    "\n",
    "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "if not isinstance(data, dict):\n",
    "    raise SystemExit(\"meta.yaml beklenen formatta deƒüil (dict).\")\n",
    "\n",
    "data[\"current_stage\"] = str(TARGET_STAGE)\n",
    "data[\"name\"] = data.get(\"name\", REG_NAME)\n",
    "data[\"version\"] = str(data.get(\"version\", TARGET_VERSION))\n",
    "\n",
    "for key in [\"latest_metrics\", \"aliases\", \"tags\"]:\n",
    "    if key in data:\n",
    "        try:\n",
    "            del data[key]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def sanitize(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): sanitize(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        return [sanitize(x) for x in obj]\n",
    "    elif isinstance(obj, (int, float, str)) or obj is None or isinstance(obj, bool):\n",
    "        return obj\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "data = sanitize(data)\n",
    "\n",
    "tmp_path = meta_dir / f\".meta.yaml.tmp-{ts}\"\n",
    "with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(\n",
    "        data, f, default_flow_style=False, allow_unicode=True, sort_keys=True\n",
    "    )\n",
    "shutil.move(str(tmp_path), str(meta_path))\n",
    "print(f\"[ok] meta.yaml g√ºncellendi ‚Üí stage='{TARGET_STAGE}'\")\n",
    "\n",
    "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    chk = yaml.safe_load(f)\n",
    "print(\"[verify] current_stage:\", chk.get(\"current_stage\"), \"| version:\", chk.get(\"version\"))\n",
    "\n",
    "print(\"\\n MLflow UI ‚Üí Models ‚Üí\", REG_NAME, \"‚Üí Versions ‚Üí v\", TARGET_VERSION,\n",
    "      \" .\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16d94766-8494-471b-9e32-9c7e82a617e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] hedef: logistics-on-time v2 ‚Üí Production\n",
      "[warn] API ile transition hata verdi: RepresenterError('cannot represent an object', <Metric: dataset_digest=None, dataset_name=None, key='prec_at_040', model_id='m-c9ddb59bf72a49aea670dc1cdd542fad', run_id='2886c2319cf747cdabdaf10edf39b111', step=0, timestamp=1758025509868, value=0.636830102622577>)\n",
      "[ok] Fallback ile Production ‚Üí stage=Production | version=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/jfs9sfcd1t56yn93r71pt2km0000gn/T/ipykernel_43869/1071797219.py:23: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "import time, shutil\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "REG_NAME = \"logistics-on-time\"\n",
    "TARGET_VERSION = None      \n",
    "ARCHIVE_OLD = True     \n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# 1) Versiyonu bul\n",
    "vers = client.search_model_versions(f\"name='{REG_NAME}'\")\n",
    "assert vers, f\"Model yok: {REG_NAME}\"\n",
    "if TARGET_VERSION is None:\n",
    "    TARGET_VERSION = str(max(int(v.version) for v in vers))\n",
    "\n",
    "print(f\"[info] hedef: {REG_NAME} v{TARGET_VERSION} ‚Üí Production\")\n",
    "\n",
    "try:\n",
    "    client.transition_model_version_stage(\n",
    "        name=REG_NAME, version=TARGET_VERSION,\n",
    "        stage=\"Production\", archive_existing_versions=ARCHIVE_OLD\n",
    "    )\n",
    "    mv = client.get_model_version(REG_NAME, TARGET_VERSION)\n",
    "    print(f\"[ok] API ile Production'a alƒ±ndƒ± ‚Üí stage={mv.current_stage}\")\n",
    "    done = True\n",
    "except Exception as e:\n",
    "    print(\"[warn] API ile transition hata verdi:\", repr(e))\n",
    "    done = False\n",
    "\n",
    "if not done:\n",
    "    reg_uri = mlflow.get_registry_uri()\n",
    "    if not reg_uri.startswith(\"file://\"):\n",
    "        raise SystemExit(f\"Registry file-store deƒüil: {reg_uri} (fallback yalnƒ±z file:// i√ßin)\")\n",
    "    base_dir = Path(reg_uri.replace(\"file://\", \"\"))\n",
    "    meta_dir = base_dir / \"models\" / REG_NAME / f\"version-{TARGET_VERSION}\"\n",
    "    meta_path = meta_dir / \"meta.yaml\"\n",
    "    assert meta_path.exists(), f\"meta.yaml yok: {meta_path}\"\n",
    "\n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    backup_path = meta_dir / f\"meta.yaml.bak-{ts}\"\n",
    "    shutil.copy2(meta_path, backup_path)\n",
    "\n",
    "    import yaml\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    if not isinstance(data, dict):\n",
    "        raise SystemExit(\"meta.yaml beklenmeyen format\")\n",
    "\n",
    "    data[\"current_stage\"] = \"Production\"\n",
    "    data[\"name\"] = data.get(\"name\", REG_NAME)\n",
    "    data[\"version\"] = str(data.get(\"version\", TARGET_VERSION))\n",
    "    for key in [\"latest_metrics\", \"aliases\", \"tags\"]:\n",
    "        if key in data:\n",
    "            del data[key]\n",
    "\n",
    "    def sanitize(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {str(k): sanitize(v) for k,v in obj.items()}\n",
    "        if isinstance(obj, (list, tuple, set)):\n",
    "            return [sanitize(x) for x in obj]\n",
    "        if isinstance(obj, (int, float, str, type(None), bool)):\n",
    "            return obj\n",
    "        return str(obj)\n",
    "\n",
    "    data = sanitize(data)\n",
    "    tmp = meta_dir / f\".meta.yaml.tmp-{ts}\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=True)\n",
    "    tmp.replace(meta_path)\n",
    "\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chk = yaml.safe_load(f)\n",
    "    print(f\"[ok] Fallback ile Production ‚Üí stage={chk.get('current_stage')} | version={chk.get('version')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e8926ef-78c4-462c-9409-776caf64c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "client.set_registered_model_alias(\"logistics-on-time\", \"Production\", 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
