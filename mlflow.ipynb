{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "879e0d46-06fa-41d6-8d08-b39166ff4e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10999, 12)\n",
      "Columns: ['ID', 'Warehouse_block', 'Mode_of_Shipment', 'Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases', 'Product_importance', 'Gender', 'Discount_offered', 'Weight_in_gms', 'Reached.on.Time_Y.N']\n",
      "   ID Warehouse_block Mode_of_Shipment  Customer_care_calls  Customer_rating  \\\n",
      "0   1               D           Flight                    4                2   \n",
      "1   2               F           Flight                    4                5   \n",
      "2   3               A           Flight                    2                2   \n",
      "\n",
      "   Cost_of_the_Product  Prior_purchases Product_importance Gender  \\\n",
      "0                  177                3                low      F   \n",
      "1                  216                2                low      M   \n",
      "2                  183                4                low      M   \n",
      "\n",
      "   Discount_offered  Weight_in_gms  Reached.on.Time_Y.N  \n",
      "0                44           1233                    1  \n",
      "1                59           3088                    1  \n",
      "2                48           3374                    1  \n",
      "\n",
      "Target (Reached.on.Time_Y.N) value counts:\n",
      "Reached.on.Time_Y.N\n",
      "1    6563\n",
      "0    4436\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dtypes:\n",
      "ID                      int64\n",
      "Warehouse_block        object\n",
      "Mode_of_Shipment       object\n",
      "Customer_care_calls     int64\n",
      "Customer_rating         int64\n",
      "Cost_of_the_Product     int64\n",
      "Prior_purchases         int64\n",
      "Product_importance     object\n",
      "Gender                 object\n",
      "Discount_offered        int64\n",
      "Weight_in_gms           int64\n",
      "Reached.on.Time_Y.N     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CSV_PATH = \"/Users/burakbozatli/Desktop/data/shippingdata.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"\\nTarget (Reached.on.Time_Y.N) value counts:\")\n",
    "print(df[\"Reached.on.Time_Y.N\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nDtypes:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7908f5-ba67-40f9-9a82-0579b20024f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hedef kolon: Reached.on.Time_Y.N (1=on-time, 0=late). Sınıf dağılımı: 6563 / 4436 → çok dengesiz değil, ama 1’ler biraz fazla.\n",
    "#Tipler: kategorikler (Warehouse_block, Mode_of_Shipment, Product_importance, Gender) object; sayısallar int. Beklenen gibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "115bb923-c2e1-4074-b621-14e96443541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse_block        0\n",
      "Mode_of_Shipment       0\n",
      "Customer_care_calls    0\n",
      "Customer_rating        0\n",
      "Cost_of_the_Product    0\n",
      "Prior_purchases        0\n",
      "Product_importance     0\n",
      "Gender                 0\n",
      "Discount_offered       0\n",
      "Weight_in_gms          0\n",
      "Reached.on.Time_Y.N    0\n",
      "OnTime                 0\n",
      "dtype: int64\n",
      "OnTime\n",
      "1    6563\n",
      "0    4436\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.copy()\n",
    "df[\"OnTime\"] = df[\"Reached.on.Time_Y.N\"]\n",
    "df = df.drop(columns=[\"ID\"], errors=\"ignore\")\n",
    "\n",
    "print(df.isna().sum().sort_values(ascending=False))\n",
    "print(df[\"OnTime\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c68ca2ac-731c-4501-a01f-3bf799bd10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical: ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']\n",
      "Numeric: ['Customer_care_calls', 'Customer_rating', 'Cost_of_the_Product', 'Prior_purchases', 'Discount_offered', 'Weight_in_gms']\n",
      "Train: (8799, 10) Test: (2200, 10) | OnTime=1 (train): 5250 of 8799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "\n",
    "y = df[\"OnTime\"]\n",
    "X = df.drop(columns=[\"OnTime\", \"Reached.on.Time_Y.N\"])\n",
    "\n",
    "cat_cols = [\"Warehouse_block\", \"Mode_of_Shipment\", \"Product_importance\", \"Gender\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numeric:\", num_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape,\n",
    "      \"| OnTime=1 (train):\", int(y_train.sum()), \"of\", y_train.shape[0])\n",
    "\n",
    "pre_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "pre_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b83ecd-d184-4e7c-9d9b-b82b2653c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR @th=0.40] acc=0.639 prec=0.706 rec=0.676 f1=0.691 auc=0.717 | fit_s=0.03s\n",
      "CM:\n",
      " [[518 369]\n",
      " [426 887]]\n",
      "\n",
      "Report @0.40:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.549     0.584     0.566       887\n",
      "           1      0.706     0.676     0.691      1313\n",
      "\n",
      "    accuracy                          0.639      2200\n",
      "   macro avg      0.627     0.630     0.628      2200\n",
      "weighted avg      0.643     0.639     0.640      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "TH_40 = 0.40\n",
    "\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    (\"prep\", pre_lr),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "t0 = time.time()\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "fit_s_lr = time.time() - t0\n",
    "\n",
    "y_proba = pipe_lr.predict_proba(X_test)[:, 1]\n",
    "y_pred  = (y_proba >= TH_40).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec  = recall_score(y_test, y_pred)\n",
    "f1   = f1_score(y_test, y_pred)\n",
    "roc  = roc_auc_score(y_test, y_proba)\n",
    "cm   = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"[LR @th=0.40] acc={acc:.3f} prec={prec:.3f} rec={rec:.3f} f1={f1:.3f} auc={roc:.3f} | fit_s={fit_s_lr:.2f}s\")\n",
    "print(\"CM:\\n\", cm)\n",
    "print(\"\\nReport @0.40:\\n\", classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46e591-582a-4a3d-88c3-feadc14ef466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC=0.717 → ayırma gücü fena değil.\n",
    "#th=0.40’ta P=0.706 / R=0.676 / F1=0.691: dengeli; ama FP=369, FN=426 (CM’den).\n",
    "#ihtiyaca göre eşiği oynatmak mantıklı (FP↓ için th↑, FN↓ için th↓)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a815ef5-b7b3-432c-8f21-b90d98a151ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Best F1 threshold ≈ 0.177 | P=0.598 R=0.998 F1=0.748\n",
      "CM @best_th:\n",
      " [[   5  882]\n",
      " [   3 1310]]\n",
      "Report @best_th:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.625     0.006     0.011       887\n",
      "           1      0.598     0.998     0.748      1313\n",
      "\n",
      "    accuracy                          0.598      2200\n",
      "   macro avg      0.611     0.502     0.379      2200\n",
      "weighted avg      0.609     0.598     0.451      2200\n",
      "\n",
      "[LR] th for recall≥0.80: 0.141 | P=0.597 R=1.000\n",
      "[[   0  887]\n",
      " [   0 1313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       887\n",
      "           1      0.597     1.000     0.748      1313\n",
      "\n",
      "    accuracy                          0.597      2200\n",
      "   macro avg      0.298     0.500     0.374      2200\n",
      "weighted avg      0.356     0.597     0.446      2200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "prec_arr, rec_arr, th_arr = precision_recall_curve(y_test, y_proba)\n",
    "f1s = 2 * (prec_arr * rec_arr) / (prec_arr + rec_arr + 1e-12)\n",
    "\n",
    "best_idx = int(f1s.argmax())\n",
    "best_th = th_arr[best_idx-1] if best_idx > 0 else 0.5\n",
    "print(f\"[LR] Best F1 threshold ≈ {best_th:.3f} | P={prec_arr[best_idx]:.3f} R={rec_arr[best_idx]:.3f} F1={f1s[best_idx]:.3f}\")\n",
    "\n",
    "y_pred_best = (y_proba >= best_th).astype(int)\n",
    "print(\"CM @best_th:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"Report @best_th:\\n\", classification_report(y_test, y_pred_best, digits=3))\n",
    "\n",
    "target_recall = 0.80\n",
    "idx = np.where(rec_arr >= target_recall)[0]\n",
    "if len(idx):\n",
    "    i = idx[0]\n",
    "    th_recall = th_arr[i-1] if i > 0 else th_arr[0]\n",
    "    y_pred_r = (y_proba >= th_recall).astype(int)\n",
    "    print(f\"[LR] th for recall≥{target_recall:.2f}: {th_recall:.3f} | P={prec_arr[i]:.3f} R={rec_arr[i]:.3f}\")\n",
    "    print(confusion_matrix(y_test, y_pred_r))\n",
    "    print(classification_report(y_test, y_pred_r, digits=3))\n",
    "else:\n",
    "    print(f\"[LR] recall≥{target_recall:.2f} sağlanamadı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eec62bbe-7027-4f6d-90e8-bcf1fc690f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2025/09/16 14:59:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLflow] Logged LR run: logistics-demo / lr-th-0p40\n"
     ]
    }
   ],
   "source": [
    "RUN_MLFLOW = True\n",
    "try:\n",
    "    import mlflow, mlflow.sklearn\n",
    "    from mlflow.models.signature import infer_signature\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "except Exception:\n",
    "    RUN_MLFLOW = False\n",
    "\n",
    "if RUN_MLFLOW:\n",
    "    ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"lr-th-0p40\"):\n",
    "        mlflow.log_param(\"model\", \"LogisticRegression\")\n",
    "        mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "        mlflow.log_param(\"threshold\", 0.40)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", float(acc))\n",
    "        mlflow.log_metric(\"precision\", float(prec))\n",
    "        mlflow.log_metric(\"recall\", float(rec))\n",
    "        mlflow.log_metric(\"f1\", float(f1))\n",
    "        mlflow.log_metric(\"roc_auc\", float(roc))\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(cm); ax.set_title(\"CM LR @th=0.40\")\n",
    "        for (i, j), v in np.ndenumerate(cm):\n",
    "            ax.text(j, i, int(v), ha=\"center\", va=\"center\")\n",
    "        p = ART_DIR / \"cm_lr_th040.png\"\n",
    "        fig.tight_layout(); fig.savefig(p, dpi=150); plt.close(fig)\n",
    "        mlflow.log_artifact(str(p), artifact_path=\"plots\")\n",
    "\n",
    "        signature = infer_signature(X_train, pipe_lr.predict(X_train))\n",
    "        mlflow.sklearn.log_model(pipe_lr, \"model\", signature=signature)\n",
    "\n",
    "    print(\"[MLflow] Logged LR run: logistics-demo / lr-th-0p40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b77c0b8-793b-40da-98cc-e33164f62fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cb4e694-3d0f-4e3e-bd37-a80ad9539cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] RF retrain done in 1.34s\n",
      "\n",
      "[RF] @th=0.40: {'th': 0.4, 'acc': 0.6213636363636363, 'prec': 0.636830102622577, 'rec': 0.8507235338918507, 'f1': 0.7283990870557548, 'auc': 0.7372549760396212, 'cm': [[250, 637], [196, 1117]]}\n",
      "[RF] @th=0.50: {'th': 0.5, 'acc': 0.6654545454545454, 'prec': 0.8312284730195177, 'rec': 0.5514089870525514, 'f1': 0.663003663003663, 'auc': 0.7372549760396212, 'cm': [[740, 147], [589, 724]]}\n",
      "\n",
      "[RF] Best F1 in 0.40–0.55: {'th': 0.4, 'f1': 0.7283990870557548, 'acc': 0.6213636363636363, 'prec': 0.636830102622577, 'rec': 0.8507235338918507, 'cm': [[250, 637], [196, 1117]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLflow] RF model logged with signature & input_example\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "\n",
    "try:\n",
    "    pre_rf\n",
    "except NameError:\n",
    "    pre_rf = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols),\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "RF_PARAMS = dict(\n",
    "    n_estimators=1000, max_depth=14, max_features=\"sqrt\",\n",
    "    min_samples_leaf=2, bootstrap=True, max_samples=0.8,\n",
    "    n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    (\"prep\", pre_rf),\n",
    "    (\"rf\", RandomForestClassifier(**RF_PARAMS))\n",
    "])\n",
    "\n",
    "t0 = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "fit_s = time.time() - t0\n",
    "print(f\"[INFO] RF retrain done in {fit_s:.2f}s\")\n",
    "\n",
    "proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def eval_at(th):\n",
    "    pred = (proba_rf >= th).astype(int)\n",
    "    return {\n",
    "        \"th\": th,\n",
    "        \"acc\": accuracy_score(y_test, pred),\n",
    "        \"prec\": precision_score(y_test, pred),\n",
    "        \"rec\":  recall_score(y_test, pred),\n",
    "        \"f1\":   f1_score(y_test, pred),\n",
    "        \"auc\":  roc_auc_score(y_test, proba_rf),\n",
    "        \"cm\":   confusion_matrix(y_test, pred)\n",
    "    }\n",
    "\n",
    "res_040 = eval_at(0.40)\n",
    "res_050 = eval_at(0.50)\n",
    "print(\"\\n[RF] @th=0.40:\", {k:(float(v) if k!='cm' else v.tolist()) for k,v in res_040.items()})\n",
    "print(\"[RF] @th=0.50:\", {k:(float(v) if k!='cm' else v.tolist()) for k,v in res_050.items()})\n",
    "\n",
    "best = {\"th\": None, \"f1\": -1}\n",
    "for th in np.arange(0.40, 0.551, 0.01):\n",
    "    pred = (proba_rf >= th).astype(int)\n",
    "    f1v = f1_score(y_test, pred)\n",
    "    if f1v > best[\"f1\"]:\n",
    "        best = {\n",
    "            \"th\": float(th),\n",
    "            \"f1\": float(f1v),\n",
    "            \"acc\": float(accuracy_score(y_test, pred)),\n",
    "            \"prec\": float(precision_score(y_test, pred)),\n",
    "            \"rec\": float(recall_score(y_test, pred)),\n",
    "            \"cm\": confusion_matrix(y_test, pred).tolist()\n",
    "        }\n",
    "print(\"\\n[RF] Best F1 in 0.40–0.55:\", best)\n",
    "\n",
    "RUN_MLFLOW = True\n",
    "try:\n",
    "    import mlflow, mlflow.sklearn\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mlflow.models.signature import infer_signature\n",
    "except Exception:\n",
    "    RUN_MLFLOW = False\n",
    "\n",
    "if RUN_MLFLOW:\n",
    "    ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    cm040 = res_040[\"cm\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cm040); ax.set_title(\"CM RF @th=0.40\")\n",
    "    for (i, j), v in np.ndenumerate(cm040): ax.text(j, i, int(v), ha=\"center\", va=\"center\")\n",
    "    p = ART_DIR / \"cm_rf_th040.png\"\n",
    "    fig.tight_layout(); fig.savefig(p, dpi=150); plt.close(fig)\n",
    "\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"rf-full-th040\"):\n",
    "        mlflow.log_params(RF_PARAMS)\n",
    "        mlflow.log_param(\"threshold\", 0.40)\n",
    "        mlflow.log_metric(\"acc_at_040\", float(res_040[\"acc\"]))\n",
    "        mlflow.log_metric(\"prec_at_040\", float(res_040[\"prec\"]))\n",
    "        mlflow.log_metric(\"rec_at_040\",  float(res_040[\"rec\"]))\n",
    "        mlflow.log_metric(\"f1_at_040\",   float(res_040[\"f1\"]))\n",
    "        mlflow.log_metric(\"auc_at_040\",  float(res_040[\"auc\"]))\n",
    "        mlflow.log_metric(\"best_f1_in_040_055\", float(best[\"f1\"]))\n",
    "        mlflow.log_artifact(str(p), artifact_path=\"plots\")\n",
    "\n",
    "        signature = infer_signature(X_train, rf.predict(X_train))\n",
    "        input_example = X_train.head(1)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=rf,\n",
    "            name=\"rf_model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "    print(\"[MLflow] RF model logged with signature & input_example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959c96f-9517-4853-8590-f278d4cd8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#th=0.40: acc=0.621, prec=0.637, rec=0.851, F1=0.728, AUC=0.737\n",
    "#→ recall güçlü (gecikmeleri daha çok yakalıyor), F1 de LR’dan yüksek (LR F1≈0.691).\n",
    "#th=0.50: acc=0.666, prec=0.831, rec=0.551, F1=0.663\n",
    "#→ precision güçlü, ama recall düşüyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "805c2297-c6f5-4c8a-bc05-0acf9394ab5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-15 permutation importance (roc_auc):\n",
      "Weight_in_gms          0.083637\n",
      "Discount_offered       0.026240\n",
      "Cost_of_the_Product    0.002189\n",
      "Mode_of_Shipment       0.000986\n",
      "Warehouse_block       -0.000744\n",
      "Gender                -0.001687\n",
      "Customer_rating       -0.002084\n",
      "Customer_care_calls   -0.003019\n",
      "Prior_purchases       -0.004328\n",
      "Product_importance    -0.008837\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "r = permutation_importance(\n",
    "    rf, X_test, y_test,\n",
    "    scoring=\"roc_auc\", n_repeats=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "feat_names = rf.named_steps[\"prep\"].get_feature_names_out()\n",
    "imp = pd.Series(r.importances_mean, index=feat_names).sort_values(ascending=False)\n",
    "\n",
    "imp.index = [s.replace(\"cat__\", \"\").replace(\"num__\", \"\") for s in imp.index]\n",
    "\n",
    "print(\"Top-15 permutation importance (roc_auc):\")\n",
    "print(imp.head(15).round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a1945b-3f9d-467b-8acf-094f4c1f029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms açık ara en faydalı sinyal.\n",
    "#Discount_offered ikinci; indirim arttıkça gecikme/“on-time” olasılığı nasıl değişiyor, kontrol etmeye değer.\n",
    "#Diğerlerinin negatif olması “kötü etkiliyor” demek değil;\n",
    "#permütasyon gürültüsü ve etkileşim/kollinearite yüzünden ortalama etki sıfır civarında \n",
    "#model onlar olmadan da benzer performansı yakalıyor olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "365bd0b5-7536-42d5-a1d4-49a1d550b07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Weight_in_gms] bin -> n, mean_proba, ontime_rate@0.5\n",
      "         bin   n  mean_proba  ontime_rate\n",
      "[1002, 1329) 220    0.688896     0.568182\n",
      "[1329, 1664) 220    0.671765     0.513636\n",
      "[1664, 2029) 220    0.669726     0.581818\n",
      "[2029, 3364) 220    0.984323     1.000000\n",
      "[3364, 4201) 220    0.730377     0.672727\n",
      "[4201, 4531) 221    0.430454     0.108597\n",
      "[4531, 4889) 219    0.425446     0.123288\n",
      "[4889, 5265) 220    0.432068     0.113636\n",
      "[5265, 5624) 220    0.429576     0.122727\n",
      "[5624, 7588) 220    0.443025     0.154545\n",
      "\n",
      "[Discount_offered] bin -> n, mean_proba, ontime_rate@0.5\n",
      "     bin   n  mean_proba  ontime_rate\n",
      "  [1, 2) 331    0.482168     0.265861\n",
      "  [2, 3) 184    0.465972     0.250000\n",
      "  [3, 4) 161    0.439662     0.136646\n",
      "  [4, 6) 334    0.476995     0.224551\n",
      "  [6, 7) 186    0.456708     0.166667\n",
      "  [7, 8) 142    0.448488     0.183099\n",
      " [8, 10) 341    0.457008     0.181818\n",
      "[10, 19)  88    0.994867     1.000000\n",
      "[19, 45) 222    0.997397     1.000000\n",
      "[45, 65) 211    0.997002     1.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_te = X_test.copy()\n",
    "X_te[\"proba_rf\"] = proba_rf\n",
    "\n",
    "def binned_table(col, q=10):\n",
    "    bins = np.unique(np.quantile(X_te[col].astype(float), np.linspace(0,1,q+1)))\n",
    "    labels = [f\"[{bins[i]:.0f}, {bins[i+1]:.0f})\" for i in range(len(bins)-1)]\n",
    "    cut = pd.cut(X_te[col].astype(float), bins=bins, include_lowest=True, labels=labels)\n",
    "    tbl = (\n",
    "        X_te.groupby(cut, observed=True)\n",
    "            .agg(n=(\"proba_rf\",\"size\"),\n",
    "                 mean_proba=(\"proba_rf\",\"mean\"),\n",
    "                 ontime_rate=(\"proba_rf\", lambda s: np.mean((s>=0.5).astype(int))))\n",
    "            .reset_index()\n",
    "            .rename(columns={col:\"bin\"})\n",
    "    )\n",
    "    return tbl\n",
    "\n",
    "tbl_w = binned_table(\"Weight_in_gms\", q=10)\n",
    "tbl_d = binned_table(\"Discount_offered\", q=10)\n",
    "\n",
    "print(\"\\n[Weight_in_gms] bin -> n, mean_proba, ontime_rate@0.5\")\n",
    "print(tbl_w.to_string(index=False))\n",
    "\n",
    "print(\"\\n[Discount_offered] bin -> n, mean_proba, ontime_rate@0.5\")\n",
    "print(tbl_d.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69908e66-88ed-460e-a651-70c5bbc12642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms: 4.2–5.6kg civarında mean_proba ≈ 0.43 ve on-time oranı çok düşük → bu aralık gecikme riski yüksek.\n",
    "#Buna karşılık 2.0–3.36kg aralığında mean_proba ~0.98 ve on-time %100 🤨\n",
    "#Discount_offered: %10+ indirimlerde mean_proba ≈ 0.995–0.997 ve on-time %100.\n",
    "#Bu da “indirim yüksekse hep zamanında” gibi basamaklı bir davranış gösteriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f0f0779-f677-46ba-84d4-3a9d4031ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnTime rate by high_disc:\n",
      " high_disc\n",
      "0    0.470981\n",
      "1    0.865906\n",
      "Name: OnTime, dtype: float64\n",
      "\n",
      "OnTime rate by weight bucket:\n",
      " w_bucket\n",
      "<2029        0.706061\n",
      "2029-3364    1.000000\n",
      "3364-4201    0.763636\n",
      "4201-5624    0.419318\n",
      ">=5624       0.409091\n",
      "Name: OnTime, dtype: float64\n",
      "\n",
      "OnTime by high_disc x Mode_of_Shipment:\n",
      "Mode_of_Shipment    Flight      Road      Ship\n",
      "high_disc                                     \n",
      "0                 0.454545  0.492126  0.469591\n",
      "1                 0.878261  0.824074  0.872385\n",
      "\n",
      "Counts by high_disc x Mode_of_Shipment:\n",
      "Mode_of_Shipment  Flight  Road  Ship\n",
      "high_disc                           \n",
      "0                    242   254  1003\n",
      "1                    115   108   478\n",
      "\n",
      "OnTime by weight bucket x Mode_of_Shipment:\n",
      "Mode_of_Shipment    Flight      Road      Ship\n",
      "w_bucket                                      \n",
      "<2029             0.696629  0.714286  0.706009\n",
      "2029-3364         1.000000  1.000000  1.000000\n",
      "3364-4201         0.676471  0.914286  0.748344\n",
      "4201-5624         0.436709  0.392157  0.421793\n",
      ">=5624            0.406250  0.450000  0.398649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/jfs9sfcd1t56yn93r71pt2km0000gn/T/ipykernel_43869/4264605827.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  print(\"\\nOnTime rate by weight bucket:\\n\", X_te.groupby(\"w_bucket\")[\"OnTime\"].mean())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_te = X_test.copy()\n",
    "X_te[\"OnTime\"] = y_test.values\n",
    "\n",
    "X_te[\"high_disc\"] = (X_te[\"Discount_offered\"] >= 10).astype(int)\n",
    "print(\"OnTime rate by high_disc:\\n\", X_te.groupby(\"high_disc\")[\"OnTime\"].mean())\n",
    "\n",
    "bins_w = [X_te[\"Weight_in_gms\"].min()-1, 2029, 3364, 4201, 5624, X_te[\"Weight_in_gms\"].max()+1]\n",
    "labels_w = [\"<2029\", \"2029-3364\", \"3364-4201\", \"4201-5624\", \">=5624\"]\n",
    "X_te[\"w_bucket\"] = pd.cut(X_te[\"Weight_in_gms\"], bins=bins_w, labels=labels_w, include_lowest=True)\n",
    "print(\"\\nOnTime rate by weight bucket:\\n\", X_te.groupby(\"w_bucket\")[\"OnTime\"].mean())\n",
    "\n",
    "print(\"\\nOnTime by high_disc x Mode_of_Shipment:\")\n",
    "print(pd.crosstab(X_te[\"high_disc\"], X_te[\"Mode_of_Shipment\"], values=X_te[\"OnTime\"], aggfunc=\"mean\"))\n",
    "\n",
    "print(\"\\nCounts by high_disc x Mode_of_Shipment:\")\n",
    "print(pd.crosstab(X_te[\"high_disc\"], X_te[\"Mode_of_Shipment\"]))\n",
    "\n",
    "print(\"\\nOnTime by weight bucket x Mode_of_Shipment:\")\n",
    "print(pd.crosstab(X_te[\"w_bucket\"], X_te[\"Mode_of_Shipment\"], values=X_te[\"OnTime\"], aggfunc=\"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca520e6-99f7-4ca9-a4d4-e6fa27739200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Discount etkisi\n",
    "#High discount (≥20–45 arası gibi) verilenlerde OnTime oranı %100’e çıkmış.\n",
    "#Buna karşılık düşük indirimlerde (1–10 arası) OnTime oranı %18–26 civarında kalıyor.\n",
    "#Yani indirim, müşteri için değil ama lojistik operasyon için güçlü bir sinyal gibi davranıyor.\n",
    "#2) Weight (ağırlık) etkisi\n",
    "#2029–3364 gr. aralığında %100 zamanında teslim var.\n",
    "#3364–4201 gr. aralığında %76 civarında.\n",
    "#Ama 4201+ gr. olduğunda oran %40’a kadar düşüyor.\n",
    "#Demek ki ağırlık arttıkça zamanında teslim ihtimali düşüyor.\n",
    "#3) Mode of Shipment (kargo tipi) × indirim\n",
    "#High discount verilenlerde bütün taşıma tipleri %82–87 arası başarıyla gidiyor.\n",
    "#Düşük discount verilenlerde %45–49 arası kalıyor.\n",
    "#Discount, shipment tipinden bağımsız olarak güçlü bir faktör.\n",
    "#4) Mode of Shipment × Weight\n",
    "#Hafif paketlerde (≤2029) bütün taşıma tipleri %70 civarında.\n",
    "#Orta ağırlıklarda (2029–3364) %100 başarı.\n",
    "#Ağır paketlerde (4200 üstü) bütün taşıma tiplerinde %39–43’e kadar düşüyor.\n",
    "#Taşıma tipinden çok ağırlık belirleyici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe77ff51-4d6d-43ab-93fe-e15751591489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: artifacts/permutation_importance.csv\n",
      "saved: artifacts/permutation_importance_top20.png\n",
      "[MLflow] logged permutation importance artifacts\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "r = permutation_importance(\n",
    "    rf, X_test, y_test,\n",
    "    scoring=\"roc_auc\", n_repeats=5, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "feat_names = rf.named_steps[\"prep\"].get_feature_names_out()\n",
    "pi = pd.Series(r.importances_mean, index=feat_names).sort_values(ascending=True)\n",
    "\n",
    "pi.index = [s.replace(\"cat__\", \"\").replace(\"num__\", \"\") for s in pi.index]\n",
    "\n",
    "pi_path = ART_DIR / \"permutation_importance.csv\"\n",
    "pi.to_csv(pi_path, header=[\"importance\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "pi.tail(20).plot(kind=\"barh\", ax=ax)\n",
    "ax.set_title(\"Permutation Importance (top 20) — scoring=roc_auc\")\n",
    "ax.set_xlabel(\"Δ roc_auc\")\n",
    "fig.tight_layout()\n",
    "pi_png = ART_DIR / \"permutation_importance_top20.png\"\n",
    "fig.savefig(pi_png, dpi=150); plt.close(fig)\n",
    "\n",
    "print(f\"saved: {pi_path}\")\n",
    "print(f\"saved: {pi_png}\")\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"rf-permutation-importance\"):\n",
    "        mlflow.log_artifact(str(pi_path), artifact_path=\"analysis\")\n",
    "        mlflow.log_artifact(str(pi_png), artifact_path=\"plots\")\n",
    "    print(\"[MLflow] logged permutation importance artifacts\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785af923-35c7-4bd0-b59a-dcb87883f5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a4cbe-b87e-44d1-ab40-5d73bd0401c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82275274-ea95-4753-99fd-9016226edfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms (~0.084 ΔAUC): açık ara en kritik sinyal. Bu özelliği bozunca test ROC-AUC ~0.084 düşüyor.\n",
    "#Discount_offered (~0.026 ΔAUC): ikinci güçlü sinyal.\n",
    "#Geri kalanı ≈0 ya da hafif negatif: tek başına bozduğunda modelin AUC’si neredeyse değişmiyor → katkıları marjinal / etkileşimlere bağımlı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc8c6b00-5c16-42d1-9589-7a12964554a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: artifacts/binned_proba_Weight_in_gms.png\n",
      "saved: artifacts/binned_table_Weight_in_gms.csv\n",
      "saved: artifacts/binned_proba_Discount_offered.png\n",
      "saved: artifacts/binned_table_Discount_offered.csv\n",
      "[MLflow] logged binned plots & tables (fixed)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "ART_DIR = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "X_te = X_test.copy()\n",
    "X_te[\"proba_rf\"] = proba_rf\n",
    "X_te[\"OnTime\"]   = y_test.values\n",
    "\n",
    "def make_binned_plot(col, q=10):\n",
    "    # quantile bin'leri ve etiketler\n",
    "    bins = np.unique(np.quantile(X_te[col].astype(float), np.linspace(0, 1, q+1)))\n",
    "    labels = [f\"[{bins[i]:.0f},{bins[i+1]:.0f})\" for i in range(len(bins)-1)]\n",
    "    cut = pd.cut(X_te[col].astype(float), bins=bins, include_lowest=True, labels=labels)\n",
    "\n",
    "    tbl = (\n",
    "        X_te.groupby(cut, observed=True)\n",
    "            .agg(n=(\"proba_rf\",\"size\"),\n",
    "                 mean_proba=(\"proba_rf\",\"mean\"),\n",
    "                 ontime_rate=(\"OnTime\",\"mean\"))\n",
    "            .reset_index()\n",
    "            .rename(columns={col:\"bin\"})\n",
    "    )\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(9, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(range(len(tbl)), tbl[\"mean_proba\"], marker=\"o\", label=\"Mean Pred Proba\")\n",
    "    ax1.plot(range(len(tbl)), tbl[\"ontime_rate\"], marker=\"s\", label=\"OnTime Rate\")\n",
    "    ax2.bar(range(len(tbl)), tbl[\"n\"], alpha=0.25, label=\"Count\")\n",
    "\n",
    "    ax1.set_title(f\"Binned probability — {col}\")\n",
    "    ax1.set_ylabel(\"Rate / Probability\")\n",
    "    ax2.set_ylabel(\"Bin Count\")\n",
    "\n",
    "    ax1.set_xticks(range(len(tbl[\"bin\"])))\n",
    "    ax1.set_xticklabels(tbl[\"bin\"], rotation=45, ha=\"right\")\n",
    "\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_png = ART_DIR / f\"binned_proba_{col}.png\"\n",
    "    out_csv = ART_DIR / f\"binned_table_{col}.csv\"\n",
    "    fig.savefig(out_png, dpi=150); plt.close(fig)\n",
    "    tbl.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"saved: {out_png}\")\n",
    "    print(f\"saved: {out_csv}\")\n",
    "    return out_png, out_csv\n",
    "\n",
    "p1_png, p1_csv = make_binned_plot(\"Weight_in_gms\", q=10)\n",
    "p2_png, p2_csv = make_binned_plot(\"Discount_offered\", q=10)\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    mlflow.set_experiment(\"logistics-demo\")\n",
    "    with mlflow.start_run(run_name=\"rf-binned-plots-fixed\"):\n",
    "        for p in [p1_png, p2_png]:\n",
    "            mlflow.log_artifact(str(p), artifact_path=\"plots\")\n",
    "        for c in [p1_csv, p2_csv]:\n",
    "            mlflow.log_artifact(str(c), artifact_path=\"analysis\")\n",
    "    print(\"[MLflow] logged binned plots & tables (fixed)\")\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d4a22-497c-4f50-8149-2ea06804e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_in_gms (tablo/grafik):\n",
    "#4.2–5.6 kg (ör. [4201,4531), [4531,4889), [4889,5265), [5265,5624)) dilimlerinde on-time rate ≈ %40–48 → belirgin risk bandı.\n",
    "#2.0–3.36 kg civarı dilimlerde oran çok yüksek.\n",
    "#Modelin mean predicted probası da aynı paterni takip ediyor → model & veri uyumlu.\n",
    "#Discount_offered (tablo/grafik):\n",
    "#%10–%19 ve %19–%45 dilimlerinde on-time rate ≈ 1.0 ve mean proba ≈ 0.995–0.997 → pratikte “garanti” bölge.\n",
    "#%1–%8 arası dilimlerde hem oran hem proba düşük/orta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43e76ce5-1e45-407e-943d-fbb47c28f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking_uri = file:///Users/burakbozatli/mlruns\n",
      "registry_uri = file:///Users/burakbozatli/mlruns\n",
      "latest version: 2 | status: READY | stage: Staging\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "REG_NAME = \"logistics-on-time\"\n",
    "print(\"tracking_uri =\", mlflow.get_tracking_uri())\n",
    "print(\"registry_uri =\", mlflow.get_registry_uri())\n",
    "\n",
    "client = MlflowClient()\n",
    "vers = client.search_model_versions(f\"name='{REG_NAME}'\")\n",
    "assert vers, \"Registry'de versiyon bulunamadı.\"\n",
    "latest = max(vers, key=lambda v: int(v.version))\n",
    "print(\"latest version:\", latest.version, \"| status:\", latest.status, \"| stage:\", latest.current_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "304144e9-a576-419e-bda3-78045cb9e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] registry_uri = file:///Users/burakbozatli/mlruns\n",
      "[info] base_dir     = /Users/burakbozatli/mlruns\n",
      "[info] hedef versiyon = v2\n",
      "[ok] yedek alındı → /Users/burakbozatli/mlruns/models/logistics-on-time/version-2/meta.yaml.bak-20250916-174353\n",
      "[ok] meta.yaml güncellendi → stage='Staging'\n",
      "[verify] current_stage: Staging | version: 2\n",
      "\n",
      " MLflow UI → Models →logistics-on-time→ Versions → v2 .\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, time, re, sys\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "try:\n",
    "    import yaml\n",
    "except Exception:\n",
    "    raise RuntimeError(\"PyYAML gerekli. Kur: pip install pyyaml\")\n",
    "\n",
    "REG_NAME   = \"logistics-on-time\" \n",
    "TARGET_STAGE = \"Staging\"         \n",
    "TARGET_VERSION = None            \n",
    "\n",
    "reg_uri = mlflow.get_registry_uri()\n",
    "if not reg_uri.startswith(\"file://\"):\n",
    "    raise SystemExit(f\"Registry file-store değil: {reg_uri} (Bu yama sadece file:// için)\")\n",
    "\n",
    "base_dir = Path(reg_uri.replace(\"file://\", \"\"))\n",
    "if not base_dir.exists():\n",
    "    raise SystemExit(f\"Registry dizini yok: {base_dir}\")\n",
    "\n",
    "print(\"[info] registry_uri =\", reg_uri)\n",
    "print(\"[info] base_dir     =\", base_dir)\n",
    "\n",
    "client = MlflowClient()\n",
    "vers = client.search_model_versions(f\"name='{REG_NAME}'\")\n",
    "if not vers:\n",
    "    raise SystemExit(f\"Model bulunamadı: {REG_NAME}\")\n",
    "\n",
    "if TARGET_VERSION is None:\n",
    "    TARGET_VERSION = max(int(v.version) for v in vers)\n",
    "print(f\"[info] hedef versiyon = v{TARGET_VERSION}\")\n",
    "\n",
    "meta_dir = base_dir / \"models\" / REG_NAME / f\"version-{TARGET_VERSION}\"\n",
    "meta_path = meta_dir / \"meta.yaml\"\n",
    "if not meta_path.exists():\n",
    "    raise SystemExit(f\"meta.yaml bulunamadı: {meta_path}\")\n",
    "\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "backup_path = meta_dir / f\"meta.yaml.bak-{ts}\"\n",
    "shutil.copy2(meta_path, backup_path)\n",
    "print(f\"[ok] yedek alındı → {backup_path}\")\n",
    "\n",
    "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "if not isinstance(data, dict):\n",
    "    raise SystemExit(\"meta.yaml beklenen formatta değil (dict).\")\n",
    "\n",
    "data[\"current_stage\"] = str(TARGET_STAGE)\n",
    "data[\"name\"] = data.get(\"name\", REG_NAME)\n",
    "data[\"version\"] = str(data.get(\"version\", TARGET_VERSION))\n",
    "\n",
    "for key in [\"latest_metrics\", \"aliases\", \"tags\"]:\n",
    "    if key in data:\n",
    "        try:\n",
    "            del data[key]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def sanitize(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): sanitize(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        return [sanitize(x) for x in obj]\n",
    "    elif isinstance(obj, (int, float, str)) or obj is None or isinstance(obj, bool):\n",
    "        return obj\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "data = sanitize(data)\n",
    "\n",
    "tmp_path = meta_dir / f\".meta.yaml.tmp-{ts}\"\n",
    "with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(\n",
    "        data, f, default_flow_style=False, allow_unicode=True, sort_keys=True\n",
    "    )\n",
    "shutil.move(str(tmp_path), str(meta_path))\n",
    "print(f\"[ok] meta.yaml güncellendi → stage='{TARGET_STAGE}'\")\n",
    "\n",
    "with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    chk = yaml.safe_load(f)\n",
    "print(\"[verify] current_stage:\", chk.get(\"current_stage\"), \"| version:\", chk.get(\"version\"))\n",
    "\n",
    "print(\"\\n MLflow UI → Models →\", REG_NAME, \"→ Versions → v\", TARGET_VERSION,\n",
    "      \" .\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16d94766-8494-471b-9e32-9c7e82a617e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] hedef: logistics-on-time v2 → Production\n",
      "[warn] API ile transition hata verdi: RepresenterError('cannot represent an object', <Metric: dataset_digest=None, dataset_name=None, key='prec_at_040', model_id='m-c9ddb59bf72a49aea670dc1cdd542fad', run_id='2886c2319cf747cdabdaf10edf39b111', step=0, timestamp=1758025509868, value=0.636830102622577>)\n",
      "[ok] Fallback ile Production → stage=Production | version=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/jfs9sfcd1t56yn93r71pt2km0000gn/T/ipykernel_43869/1071797219.py:23: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "import time, shutil\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "REG_NAME = \"logistics-on-time\"\n",
    "TARGET_VERSION = None      \n",
    "ARCHIVE_OLD = True     \n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# 1) Versiyonu bul\n",
    "vers = client.search_model_versions(f\"name='{REG_NAME}'\")\n",
    "assert vers, f\"Model yok: {REG_NAME}\"\n",
    "if TARGET_VERSION is None:\n",
    "    TARGET_VERSION = str(max(int(v.version) for v in vers))\n",
    "\n",
    "print(f\"[info] hedef: {REG_NAME} v{TARGET_VERSION} → Production\")\n",
    "\n",
    "try:\n",
    "    client.transition_model_version_stage(\n",
    "        name=REG_NAME, version=TARGET_VERSION,\n",
    "        stage=\"Production\", archive_existing_versions=ARCHIVE_OLD\n",
    "    )\n",
    "    mv = client.get_model_version(REG_NAME, TARGET_VERSION)\n",
    "    print(f\"[ok] API ile Production'a alındı → stage={mv.current_stage}\")\n",
    "    done = True\n",
    "except Exception as e:\n",
    "    print(\"[warn] API ile transition hata verdi:\", repr(e))\n",
    "    done = False\n",
    "\n",
    "if not done:\n",
    "    reg_uri = mlflow.get_registry_uri()\n",
    "    if not reg_uri.startswith(\"file://\"):\n",
    "        raise SystemExit(f\"Registry file-store değil: {reg_uri} (fallback yalnız file:// için)\")\n",
    "    base_dir = Path(reg_uri.replace(\"file://\", \"\"))\n",
    "    meta_dir = base_dir / \"models\" / REG_NAME / f\"version-{TARGET_VERSION}\"\n",
    "    meta_path = meta_dir / \"meta.yaml\"\n",
    "    assert meta_path.exists(), f\"meta.yaml yok: {meta_path}\"\n",
    "\n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    backup_path = meta_dir / f\"meta.yaml.bak-{ts}\"\n",
    "    shutil.copy2(meta_path, backup_path)\n",
    "\n",
    "    import yaml\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    if not isinstance(data, dict):\n",
    "        raise SystemExit(\"meta.yaml beklenmeyen format\")\n",
    "\n",
    "    data[\"current_stage\"] = \"Production\"\n",
    "    data[\"name\"] = data.get(\"name\", REG_NAME)\n",
    "    data[\"version\"] = str(data.get(\"version\", TARGET_VERSION))\n",
    "    for key in [\"latest_metrics\", \"aliases\", \"tags\"]:\n",
    "        if key in data:\n",
    "            del data[key]\n",
    "\n",
    "    def sanitize(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {str(k): sanitize(v) for k,v in obj.items()}\n",
    "        if isinstance(obj, (list, tuple, set)):\n",
    "            return [sanitize(x) for x in obj]\n",
    "        if isinstance(obj, (int, float, str, type(None), bool)):\n",
    "            return obj\n",
    "        return str(obj)\n",
    "\n",
    "    data = sanitize(data)\n",
    "    tmp = meta_dir / f\".meta.yaml.tmp-{ts}\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(data, f, default_flow_style=False, allow_unicode=True, sort_keys=True)\n",
    "    tmp.replace(meta_path)\n",
    "\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chk = yaml.safe_load(f)\n",
    "    print(f\"[ok] Fallback ile Production → stage={chk.get('current_stage')} | version={chk.get('version')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e8926ef-78c4-462c-9409-776caf64c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "client.set_registered_model_alias(\"logistics-on-time\", \"Production\", 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
